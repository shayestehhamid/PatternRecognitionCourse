{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "mat_data = sio.loadmat(\"DD.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1178\n"
     ]
    }
   ],
   "source": [
    "print len(mat_data[\"ldd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1178\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for index in xrange(mat_data[\"DD\"].shape[1]):\n",
    "    #print sample\n",
    "    sample = mat_data[\"DD\"][0, index]\n",
    "    #print index\n",
    "    col = 0\n",
    "    ss = 0\n",
    "    for l in sample[2]:\n",
    "        ss += 1\n",
    "    #print ss\n",
    "    graph = Graph(ss)\n",
    "    graph.title = str(index)\n",
    "    graph.res = mat_data[\"ldd\"][index][0]\n",
    "    \n",
    "    col = 0\n",
    "    for l in sample[2]:\n",
    "\n",
    "        for d in l[0][0]:\n",
    "            #print d, col\n",
    "            graph.matrix[d-1][col] = 1\n",
    "            \n",
    "        col += 1\n",
    "    data.append(graph)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'svm_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-344aef588d84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mten_fold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-137-344aef588d84>\u001b[0m in \u001b[0;36mten_fold\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0msvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'svm_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "def ten_fold(data):\n",
    "    from random import randint\n",
    "    no = len(data)\n",
    "    test_index = []\n",
    "    while len(test_index) < len(data)/10:\n",
    "        t = randint(0, len(data))\n",
    "        if t not in test_index:\n",
    "            test_index.append(t)\n",
    "    test_data = [data[i] for i in test_index]\n",
    "    train_data = [d for d in data if d not in test_data]\n",
    "    \n",
    "    \n",
    "    svm = svm_model(train_data)\n",
    "    print get_accuracy(test_data)\n",
    "\n",
    "ten_fold(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def svm(data):\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    train_data = []\n",
    "    res_data = []\n",
    "    for d in data:\n",
    "        train_data.append(d.features)\n",
    "        res_data.append(d.res)\n",
    "\n",
    "    train_data = np.array(train_data)\n",
    "    res_data = np.array(res_data)\n",
    "\n",
    "    svm = SVC(kernel='rbf')\n",
    "    svm.fit(train_data, res_data)\n",
    "    #self.svm_model = svm\n",
    "    return svm\n",
    "\n",
    "\n",
    "def get_accuracy(test_data, svm_model):\n",
    "    data = []\n",
    "    res_data = []\n",
    "    for d in test_data:\n",
    "        data.append(d.features)\n",
    "        res_data.append(d.res)\n",
    "\n",
    "    data = np.array(data)\n",
    "    res_data = np.array(res_data)\n",
    "\n",
    "    pre_res = svm_model.predict(data)\n",
    "    return sum(pre_res.ravel() == res_data.ravel())/float(len(data))\n",
    "\n",
    "\n",
    "class Graph():\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        self.title = \"\"\n",
    "        self.nodes = ['ff' for x in xrange(n)]\n",
    "        self.matrix = [[0 for i in xrange(n)] for x in xrange(n)]\n",
    "        self.res = 0\n",
    "        self.deg = []\n",
    "        self.N = n\n",
    "        \n",
    "        self.distance_value = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.features = []\n",
    "        self.svm_model = None\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __run__(self):\n",
    "        \n",
    "        \n",
    "        for i in xrange(self.N):\n",
    "            self.distance_value.append(self.distances(i)[1])\n",
    "        self.compute_deg()\n",
    "        \n",
    "        self.features.append(self.ave_deg()) # f-1\n",
    "        self.features.append(self.ave_clustering_coeffitient()) # f-2\n",
    "        self.features.extend(self.ave_max_min_effective_eccentricity()) # f-3, f-4, f-5\n",
    "        self.features.append(self.ave_path_len()) # f-6\n",
    "        ####################### f-7 is left!\n",
    "        self.features.append(self.central_point())\n",
    "        self.features.append(self.giant_connected_ratio()) # f-8\n",
    "        self.features.append(self.percent_isol_node()) # f-9\n",
    "        self.features.append(self.percent_end_point()) # f-10\n",
    "        self.features.append(self.node_no()) # f-11\n",
    "        self.features.append(self.edge_no()) # f-12\n",
    "        self.features.extend(self.eigenValue_features()) # f-13, f-14, f-15, f-16, f-17\n",
    "        #self.features.append(self.label_entropy()) # f-18\n",
    "        #self.features.append(self.ave_impurity_deg()) # f-19\n",
    "        #self.features.append(self.link_impurity()) # f-20\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.title\n",
    "    \n",
    "    \n",
    "    def compute_deg(self):\n",
    "        for node in self.matrix:\n",
    "            self.deg.append(sum([1 for x in node if x > 0]))\n",
    "            \n",
    "    \n",
    "    def ave_deg(self): #f-1\n",
    "        return sum(self.deg)/float(self.N)\n",
    "\n",
    "    \n",
    "    def neighbors(self, x): #helper function\n",
    "        return [i for i in xrange(self.N) if self.matrix[x][i] > 0]\n",
    "    \n",
    "    \n",
    "    def dfs(self, root, seen): #helper function\n",
    "        seen.add(root)\n",
    "        res = 1\n",
    "        for x in self.neighbors(root):\n",
    "            if x not in seen:\n",
    "                res += self.dfs(x, seen)\n",
    "        return res\n",
    "                \n",
    "    \n",
    "    def count_cluster(self, x): # helper function\n",
    "        cn = 0\n",
    "        for nghb in self.neighbors(x):\n",
    "            for n2 in self.neighbors(nghb):\n",
    "                if n2 != x and self.matrix[n2][x]:\n",
    "                    cn += 1\n",
    "        return cn\n",
    "    \n",
    "    \n",
    "    def ave_clustering_coeffitient(self): #f-2\n",
    "        ss = 0.0\n",
    "        for node in xrange(self.N):\n",
    "            ss += ((self.count_cluster(node))/((self.deg[node]**2 - self.deg[node])/2)) if (self.deg[node] != 0 and self.deg[node] != 1) else 0\n",
    "        return ss/self.N\n",
    "    \n",
    "    \n",
    "    def distances(self, root): # helper function\n",
    "        froot = root\n",
    "        distance = [0 for i in xrange(self.N)]\n",
    "        distance[root] = 0\n",
    "        stack = [root]\n",
    "        # append to add, pop to remove\n",
    "        while len(stack):\n",
    "            root = stack.pop()\n",
    "            for nghb in self.neighbors(root):\n",
    "                if not distance[nghb]:\n",
    "                    distance[nghb] += distance[root] + 1\n",
    "                    stack.append(nghb)\n",
    "        \n",
    "        \n",
    "        return froot, distance\n",
    "    \n",
    "    \n",
    "    def effective_eccentricity(self, root): # helper function ########### get to check!\n",
    "        distance = sorted(self.distance_value[root], reverse=True)\n",
    "        #print distance, root\n",
    "        \n",
    "        #print distance, distance[((self.N)/10)]\n",
    "        \n",
    "        return distance[(self.N)/10]\n",
    "        \n",
    "    \n",
    "    \n",
    "    def ave_max_min_effective_eccentricity(self): #f-3, f-4, f-5 ### has  to get check!!\n",
    "        ecc = []\n",
    "        for x in xrange(self.N):\n",
    "            ecc.append(self.effective_eccentricity(x))\n",
    "        \n",
    "        return sum(ecc)/float(self.N) ,max(ecc), min(ecc)\n",
    "    \n",
    "    \n",
    "    def ave_path_len(self): #f-6\n",
    "        closeness = 0.0\n",
    "        for x in xrange(self.N):\n",
    "            dist = self.distance_value[x]\n",
    "            closeness += (float(self.N-1)/(sum(dist)))\n",
    "        return closeness/self.N\n",
    "        \n",
    "    \n",
    "    def central_point(self): #f-7\n",
    "        ds = []\n",
    "        for x in self.distance_value:\n",
    "            ds.extend(x)\n",
    "        ds = sorted(ds, reverse=True)\n",
    "        rad = ds[len(ds)/10]\n",
    "        cn = 0\n",
    "        for x in self.distance_value:\n",
    "            if max(x) == rad:\n",
    "                cn += 1\n",
    "        return cn/float(self.N)\n",
    "        \n",
    "        \n",
    "    def giant_connected_ratio(self): #f-8\n",
    "        seen = set()\n",
    "        size = 0\n",
    "        for i in xrange(self.N):\n",
    "            if i in seen:\n",
    "                continue\n",
    "            else:\n",
    "                size = max(size, self.dfs(i, set()))\n",
    "        return float(size)/self.N\n",
    "\n",
    "    \n",
    "    def percent_isol_node(self): #f-9\n",
    "        return self.deg.count(0) / float(self.N)\n",
    "    \n",
    "    def percent_end_point(self): #f-10\n",
    "        return self.deg.count(1) / float(self.N)\n",
    "\n",
    "    def node_no(self): #f-11\n",
    "        return self.N\n",
    "\n",
    "    def edge_no(self): #f-12\n",
    "        return sum(self.deg)/2\n",
    "    \n",
    "    \n",
    "    def eigen_values(self): # helper function\n",
    "        gg = np.array(self.matrix)\n",
    "        for i in xrange(gg.shape[0]):\n",
    "            for j in xrange(gg.shape[1]):\n",
    "                gg[i, j] = 1 if gg[i, j] != 0 else 0\n",
    "        return np.sort(np.linalg.eigvals(gg))[::-1]\n",
    "    \n",
    "    \n",
    "    def eigenValue_features(self): #f-13, f-14, f-15, f-16, f-17\n",
    "        eig_val = self.eigen_values()\n",
    "        fs_eig = eig_val[0]\n",
    "        sc_eig = eig_val[1]\n",
    "        trace = np.sum(eig_val)\n",
    "        energy = np.sum(eig_val**2)\n",
    "        uniques = np.unique(eig_val).shape[0]\n",
    "        return [fs_eig, sc_eig, trace, energy, uniques]\n",
    "    \n",
    "    \n",
    "    def label_entropy(self): # f-18\n",
    "        import math\n",
    "        labels = []\n",
    "        for l in self.nodes:\n",
    "            if l not in labels:\n",
    "                labels.append(l)\n",
    "        \n",
    "        res = 0.0\n",
    "        for x in labels:\n",
    "            p = self.nodes.count(x)/float(self.N)\n",
    "            res += (p)*(math.log(p))\n",
    "        return -1 * res\n",
    "    \n",
    "    \n",
    "    def impurity_deg(self, root): # helper function\n",
    "        deg = 0\n",
    "        for x in xrange(self.N):\n",
    "            if self.nodes[root] != self.nodes[x]:\n",
    "                deg += 1\n",
    "        return deg\n",
    "\n",
    "    def ave_impurity_deg(self): # f-19\n",
    "        deg = 0.0\n",
    "        for x in xrange(self.N):\n",
    "            deg += self.impurity_deg(x)\n",
    "        return deg/float(self.N)\n",
    "    \n",
    "    def link_impurity(self): # f-20\n",
    "        d = 0\n",
    "        for i in xrange(self.N):\n",
    "            for j in xrange(self.N):\n",
    "                d += 1 if self.nodes[i] != self.nodes[j] else 0\n",
    "        return float(d)/(sum(self.deg)*2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
