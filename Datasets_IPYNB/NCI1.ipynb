{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4110\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fandogh/anaconda/lib/python2.7/site-packages/networkx/algorithms/assortativity/correlation.py:285: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (xy*(M-ab)).sum()/numpy.sqrt(vara*varb)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "d = sio.loadmat(\"NCI1.mat\")\n",
    "cnd = 0\n",
    "res = d[\"lnci1\"]\n",
    "sample_index = 0\n",
    "all_data = []\n",
    "print len(d[\"NCI1\"][0])\n",
    "for g in d[\"NCI1\"][0]:\n",
    "    \n",
    "    if cnd % 100 == 0:\n",
    "        print cnd\n",
    "    \n",
    "    cnd += 1\n",
    "    x = g[1].toarray()\n",
    "    #print x.shape\n",
    "    tt = d[\"NCI1\"][0][sample_index][0][0][0][0]\n",
    "    new_graph = Graph(len(tt))\n",
    "    for i in xrange(len(tt)):\n",
    "        new_graph.nodes[i] = tt[i][0]\n",
    "    \n",
    "    for row in xrange(x.shape[0]):\n",
    "        for col in xrange(x.shape[1]):\n",
    "            new_graph.matrix[row][col] = x[row, col]\n",
    "    new_graph.res = res[sample_index]\n",
    "    new_graph.__run__()\n",
    "    all_data.append(new_graph)\n",
    "            \n",
    "    sample_index += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leave it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sizes_res = {None: {no_normal: [], z_normal:[], range_normal:[]}, 20:{no_normal: [], z_normal:[], range_normal:[]}}\n",
    "effectiveness = {no_normal: [], z_normal:[], range_normal:[]}\n",
    "for res_ in sizes_res:\n",
    "    for func in sizes_res[res_]:\n",
    "        for _ in xrange(10):\n",
    "            sizes_res[res_][func].extend(ten_fold(all_data, func, res_))\n",
    "            effectiveness[func].append(svm_wrapper(all_data, func, res_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 <function z_normal at 0x7fea5b087b90>\n",
      "0.500486618005\n",
      "0.0237260587699\n",
      "20 <function no_normal at 0x7fea8413af50>\n",
      "0.500486618005\n",
      "0.0231859564588\n",
      "20 <function range_normal at 0x7fea5b0877d0>\n",
      "0.500486618005\n",
      "0.0252444082662\n",
      "None <function z_normal at 0x7fea5b087b90>\n",
      "0.500486618005\n",
      "0.0215778187911\n",
      "None <function no_normal at 0x7fea8413af50>\n",
      "0.500486618005\n",
      "0.022226513755\n",
      "None <function range_normal at 0x7fea5b0877d0>\n",
      "0.500486618005\n",
      "0.0210838166237\n"
     ]
    }
   ],
   "source": [
    "for k in sizes_res:\n",
    "    d = sizes_res[k]\n",
    "    for _ in d:\n",
    "        print k, _\n",
    "        xx = np.array(d[_])\n",
    "        print np.mean(xx)\n",
    "        print np.var(xx)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## result without 21 to 30 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77201946472\n",
      "0.0195360614756\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print np.mean(results)\n",
    "print np.var(results)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def no_normal(data):\n",
    "    return data\n",
    "\n",
    "\n",
    "def range_normal(data):\n",
    "    r_data = np.ndarray((data.shape[0], data.shape[1])).astype('float64')\n",
    "    for i in xrange(data.shape[1]):\n",
    "        \n",
    "        #print np.max(data[:, i])\n",
    "        dd = np.max(data[:, i] - np.min(data[:, i]))\n",
    "        \n",
    "        r_data[:, i] = ((data[:, i] - np.min(data[:, i]))/(dd)) if dd != 0 else np.ones((data.shape[0]))\n",
    "\n",
    "    return r_data\n",
    "\n",
    "\n",
    "def z_normal(data):\n",
    "    z_data = np.ndarray((data.shape[0], data.shape[1]))\n",
    "    for i in xrange(data.shape[1]):\n",
    "        variance = np.var(data[:, i])\n",
    "        z_data[:, i] = (data[:, i] - np.mean(data[:, i]))/variance if variance != 0 else np.zeros((data.shape[0]))\n",
    "    return z_data\n",
    "\n",
    "\n",
    "def svm_wrapper(data, normal_func,  size=None):\n",
    "    from sklearn.feature_selection import RFECV\n",
    "    import sklearn\n",
    "    \n",
    "    train_data = []\n",
    "    res_data = []\n",
    "    for d in data:\n",
    "        train_data.append(d.features if size==None else d.features[:size])\n",
    "        res_data.append(d.res)\n",
    "    train_data = np.array(train_data)\n",
    "    res_data = np.array(res_data).ravel()\n",
    "    mmf = []\n",
    "    for col in xrange(train_data.shape[1]):\n",
    "        fft = train_data[:, col]\n",
    "        mmf.append(sklearn.metrics.mutual_info_score(res_data, fft))\n",
    "    \n",
    "    return mmf\n",
    "    \n",
    "\n",
    "def ten_fold(data, normal_func, size=None):\n",
    "    import random\n",
    "    from random import randint\n",
    "    \n",
    "    no = len(data)\n",
    "    indices = range(no)\n",
    "    random.shuffle(indices)\n",
    "    acc = []\n",
    "    for time in xrange(10):\n",
    "        test_index = indices[int(time * no/10):int((time+1) * no/10)]\n",
    "        test_data = [data[i] for i in test_index]\n",
    "        #train_data = [d for d in data if d not in test_data]\n",
    "        train_data = [data[i] for i in indices if i not in test_data]\n",
    "        svm = svm_model(train_data, normal_func, size)\n",
    "        acc.append(get_accuracy(test_data, svm, normal_func, size))\n",
    "        \n",
    "    return acc\n",
    "\n",
    "\n",
    "def svm_model(data, normal_func, size=None):\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    train_data = []\n",
    "    res_data = []\n",
    "    for d in data:\n",
    "        train_data.append(d.features if size==None else d.features[:size])\n",
    "        res_data.append(d.res)\n",
    "    #print train_data\n",
    "    \n",
    "    train_data = np.array(train_data)\n",
    "    \n",
    "    for row in xrange(train_data.shape[0]):\n",
    "        for col in xrange(train_data.shape[1]):\n",
    "            train_data[row, col] = 0\n",
    "    \n",
    "    res_data = np.array(res_data).ravel()\n",
    "    train_data = normal_func(train_data)\n",
    "    svm = SVC(kernel='rbf')\n",
    "    svm.fit(train_data, res_data)\n",
    "    #self.svm_model = svm\n",
    "    return svm\n",
    "\n",
    "\n",
    "def get_accuracy(test_data, svm_model, normal_func, size=None):\n",
    "    data = []\n",
    "    res_data = []\n",
    "    for d in test_data:\n",
    "        data.append(d.features if size == None else d.features[:size])\n",
    "        res_data.append(d.res)\n",
    "\n",
    "    data = np.array(data)\n",
    "    \n",
    "    for row in xrange(data.shape[0]):\n",
    "        for col in xrange(data.shape[1]):\n",
    "            data[row, col] = 0\n",
    "    \n",
    "    data = normal_func(data)\n",
    "    res_data = np.array(res_data)\n",
    "    \n",
    "\n",
    "    pre_res = svm_model.predict(data)\n",
    "    return sum(pre_res.ravel() == res_data.ravel())/float(len(data))\n",
    "\n",
    "\n",
    "class Graph():\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        self.title = \"\"\n",
    "        self.nodes = [None for x in xrange(n)]\n",
    "        self.matrix = [[0 for i in xrange(n)] for x in xrange(n)]\n",
    "        self.res = 0\n",
    "        self.deg = []\n",
    "        self.N = n\n",
    "        self.eig = None\n",
    "        self.distance_value = []\n",
    "        \n",
    "        \n",
    "        self.ng = None\n",
    "        self.features = []\n",
    "        self.svm_model = None\n",
    "        \n",
    "    \n",
    "    def networkx_creator(self): #helper function! needed!\n",
    "        \n",
    "        self.ng = nx.Graph()\n",
    "        if self.nodes[0]:\n",
    "            self.ng.add_nodes_from(self.nodes)\n",
    "        else:\n",
    "            for i in xrange(self.N):\n",
    "                self.ng.add_node(i)\n",
    "        for row in xrange(len(self.matrix)):\n",
    "            for col in xrange(len(self.matrix)):\n",
    "                if self.matrix[row][col] and row <= col:\n",
    "                    self.ng.add_edge(row, col)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    def __run__(self):\n",
    "        \n",
    "        \n",
    "        for i in xrange(self.N):\n",
    "            self.distance_value.append(self.distances(i)[1])\n",
    "        self.compute_deg()\n",
    "        \n",
    "        self.networkx_creator()\n",
    "        \n",
    "        self.features.append(self.ave_deg()) # f-1\n",
    "        self.features.append(self.ave_clustering_coeffitient()) # f-2\n",
    "        self.features.extend(self.ave_max_min_effective_eccentricity()) # f-3, f-4, f-5\n",
    "        self.features.append(self.ave_path_len()) # f-6\n",
    "        \n",
    "        self.features.append(self.central_point()) #f-7\n",
    "        self.features.append(self.giant_connected_ratio()) # f-8\n",
    "        self.features.append(self.percent_isol_node()) # f-9\n",
    "        self.features.append(self.percent_end_point()) # f-10\n",
    "        self.features.append(self.node_no()) # f-11\n",
    "        self.features.append(self.edge_no()) # f-12\n",
    "        self.features.extend(self.eigenValue_features()) # f-13, f-14, f-15, f-16, f-17\n",
    "        self.features.append(self.label_entropy()) # f-18\n",
    "        self.features.append(self.ave_impurity_deg()) # f-19\n",
    "        self.features.append(self.link_impurity()) # f-20\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.features.append(self.eigen_exponent()) #f-21\n",
    "        self.features.append(self.hop_plot()) #f-22\n",
    "        self.features.append(self.ave_current_flow_closeness()) #f-23\n",
    "        self.features.append(self.deg_assortativity_coefficient()) #f-24\n",
    "        self.features.append(self.no_maximal_clique()) #f-25\n",
    "        self.features.append(self.ave_neigh_deg()) #f-26\n",
    "        self.features.append(self.transitivity()) #f-27\n",
    "        \n",
    "        self.features.append(self.periphery()) #f-28\n",
    "        self.features.append(self.cycle_basis()) #f-29\n",
    "        self.features.append(self.square_clustering_coefficient()) #f-30\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.title\n",
    "    \n",
    "    \n",
    "    def compute_deg(self):\n",
    "        for node in self.matrix:\n",
    "            self.deg.append(sum([1 for x in node if x > 0]))\n",
    "            \n",
    "    \n",
    "    def ave_deg(self): #f-1\n",
    "        return sum(self.deg)/float(self.N)\n",
    "\n",
    "    \n",
    "    def neighbors(self, x): #helper function\n",
    "        return [i for i in xrange(self.N) if self.matrix[x][i] > 0]\n",
    "    \n",
    "    \n",
    "    def dfs(self, root, seen): #helper function\n",
    "        seen.add(root)\n",
    "        res = 1\n",
    "        for x in self.neighbors(root):\n",
    "            if x not in seen:\n",
    "                res += self.dfs(x, seen)\n",
    "        return res\n",
    "                \n",
    "    \n",
    "    def count_cluster(self, x): # helper function\n",
    "        cn = 0\n",
    "        for nghb in self.neighbors(x):\n",
    "            for n2 in self.neighbors(nghb):\n",
    "                if n2 != x and self.matrix[n2][x]:\n",
    "                    cn += 1\n",
    "        return cn\n",
    "    \n",
    "    \n",
    "    def ave_clustering_coeffitient(self): #f-2\n",
    "        ss = 0.0\n",
    "        for node in xrange(self.N):\n",
    "            ss += ((self.count_cluster(node))/((self.deg[node]**2 - self.deg[node])/2)) if (self.deg[node] != 0 and self.deg[node] != 1) else 0\n",
    "        return ss/self.N\n",
    "    \n",
    "    \n",
    "    def distances(self, root): # helper function\n",
    "        froot = root\n",
    "        distance = [0 for i in xrange(self.N)]\n",
    "        distance[root] = 0\n",
    "        stack = [root]\n",
    "        # append to add, pop to remove\n",
    "        while len(stack):\n",
    "            root = stack.pop()\n",
    "            for nghb in self.neighbors(root):\n",
    "                if not distance[nghb]:\n",
    "                    distance[nghb] += distance[root] + 1\n",
    "                    stack.append(nghb)\n",
    "        \n",
    "        \n",
    "        return froot, distance\n",
    "    \n",
    "    \n",
    "    def effective_eccentricity(self, root): # helper function ########### get to check!\n",
    "        distance = sorted(self.distance_value[root], reverse=True)\n",
    "        #print distance, root\n",
    "        \n",
    "        #print distance, distance[((self.N)/10)]\n",
    "        \n",
    "        return distance[(self.N)/10]\n",
    "        \n",
    "    \n",
    "    \n",
    "    def ave_max_min_effective_eccentricity(self): #f-3, f-4, f-5 ### has  to get check!!\n",
    "        ecc = []\n",
    "        for x in xrange(self.N):\n",
    "            ecc.append(self.effective_eccentricity(x))\n",
    "        \n",
    "        return sum(ecc)/float(self.N) ,max(ecc), min(ecc)\n",
    "    \n",
    "    \n",
    "    def ave_path_len(self): #f-6\n",
    "        closeness = 0.0\n",
    "        for x in xrange(self.N):\n",
    "            dist = self.distance_value[x]\n",
    "            closeness += (float(self.N-1)/(sum(dist))) if sum(dist) else 0\n",
    "        return closeness/self.N\n",
    "        \n",
    "    \n",
    "    def central_point(self): #f-7\n",
    "        ds = []\n",
    "        for x in self.distance_value:\n",
    "            ds.extend(x)\n",
    "        ds = sorted(ds, reverse=True)\n",
    "        rad = ds[len(ds)/10]\n",
    "        cn = 0\n",
    "        for x in self.distance_value:\n",
    "            if max(x) == rad:\n",
    "                cn += 1\n",
    "        return cn/float(self.N)\n",
    "        \n",
    "        \n",
    "    def giant_connected_ratio(self): #f-8\n",
    "        seen = set()\n",
    "        size = 0\n",
    "        for i in xrange(self.N):\n",
    "            if i in seen:\n",
    "                continue\n",
    "            else:\n",
    "                size = max(size, self.dfs(i, set()))\n",
    "        return float(size)/self.N\n",
    "\n",
    "    \n",
    "    def percent_isol_node(self): #f-9\n",
    "        return self.deg.count(0) / float(self.N)\n",
    "    \n",
    "    \n",
    "    def percent_end_point(self): #f-10\n",
    "        return self.deg.count(1) / float(self.N)\n",
    "\n",
    "    \n",
    "    def node_no(self): #f-11\n",
    "        return self.N\n",
    "\n",
    "    \n",
    "    def edge_no(self): #f-12\n",
    "        return sum(self.deg)/2\n",
    "    \n",
    "    \n",
    "    def eigen_values(self): # helper function\n",
    "        gg = np.array(self.matrix)\n",
    "        for i in xrange(gg.shape[0]):\n",
    "            for j in xrange(gg.shape[1]):\n",
    "                gg[i, j] = 1 if gg[i, j] != 0 else 0\n",
    "        return np.sort(np.linalg.eigvals(gg))[::-1]\n",
    "    \n",
    "    \n",
    "    def eigenValue_features(self): #f-13, f-14, f-15, f-16, f-17\n",
    "        eig_val = self.eigen_values()\n",
    "        self.eig = eig_val\n",
    "        fs_eig = eig_val[0]\n",
    "        sc_eig = eig_val[1]\n",
    "        trace = np.sum(eig_val)\n",
    "        energy = np.sum(eig_val**2)\n",
    "        uniques = np.unique(eig_val).shape[0]\n",
    "        return [fs_eig, sc_eig, trace, energy, uniques]\n",
    "    \n",
    "    \n",
    "    def label_entropy(self): # f-18\n",
    "        import math\n",
    "        labels = []\n",
    "        for l in self.nodes:\n",
    "            if l not in labels:\n",
    "                labels.append(l)\n",
    "        \n",
    "        res = 0.0\n",
    "        for x in labels:\n",
    "            p = self.nodes.count(x)/float(self.N)\n",
    "            res += (p)*(math.log(p))\n",
    "        return -1 * res\n",
    "    \n",
    "    \n",
    "    def impurity_deg(self, root): # helper function\n",
    "        deg = 0\n",
    "        for x in xrange(self.N):\n",
    "            if self.nodes[root] != self.nodes[x]:\n",
    "                deg += 1\n",
    "        return deg\n",
    "\n",
    "    def ave_impurity_deg(self): # f-19\n",
    "        deg = 0.0\n",
    "        for x in xrange(self.N):\n",
    "            deg += self.impurity_deg(x)\n",
    "        return deg/float(self.N)\n",
    "    \n",
    "    def link_impurity(self): # f-20\n",
    "        d = 0\n",
    "        for i in xrange(self.N):\n",
    "            for j in xrange(self.N):\n",
    "                d += 1 if self.nodes[i] != self.nodes[j] else 0\n",
    "        return float(d)/(sum(self.deg)*2)\n",
    "    \n",
    "    \n",
    "    def eigen_exponent(self): #f-21\n",
    "        import math\n",
    "        from scipy.optimize import curve_fit\n",
    "        x = [i for i in range(1, len(self.eig)+1)]\n",
    "        y = [t.real for t in self.eig]\n",
    "        \n",
    "        def f(x, A, B):\n",
    "            return A*x + B\n",
    "\n",
    "        A, B = curve_fit(f, x, y)[0]\n",
    "        return A\n",
    "    \n",
    "    \n",
    "    def hop_plot(self): #f-22\n",
    "        import math\n",
    "        from scipy.optimize import curve_fit\n",
    "        no_couples = []\n",
    "        for i in xrange(self.N):\n",
    "            cn_i = 0\n",
    "            for l in self.distance_value:\n",
    "                cn = l.count(i)\n",
    "                cn_i += int((cn*(cn-1))/2)\n",
    "            no_couples.append(cn_i)\n",
    "        x = [i for i in xrange(self.N)]\n",
    "        y = [s.real for s in no_couples]\n",
    "        \n",
    "        def f(x, A, B):\n",
    "            return A*x + B\n",
    "        \n",
    "        A, B = curve_fit(f, x, y)[0]\n",
    "        return A\n",
    "    \n",
    "    \n",
    "    def ave_current_flow_closeness(self): #f-23\n",
    "        try:\n",
    "            d = nx.current_flow_closeness_centrality(self.ng)\n",
    "            return sum(d.values())/float(self.N)\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    def deg_assortativity_coefficient(self): #f-24\n",
    "        return nx.degree_assortativity_coefficient(self.ng)\n",
    "    \n",
    "    \n",
    "    def no_maximal_clique(self): #f-25\n",
    "        cn = 0\n",
    "        for l in nx.find_cliques(self.ng):\n",
    "            cn += 1\n",
    "        return cn\n",
    "     \n",
    "        \n",
    "    def ave_neigh_deg(self): #f-26\n",
    "        ans = 0.0\n",
    "        for i in xrange(self.N):\n",
    "            dd = 0.1\n",
    "            for j in xrange(len(self.matrix[i])):\n",
    "                if self.matrix[i][j]:\n",
    "                    dd += self.deg[j]\n",
    "            ans += (dd/self.deg[i]) if self.deg[i] else 0\n",
    "        return ans/self.N\n",
    "    \n",
    "    \n",
    "    \n",
    "    def transitivity(self): #f-27\n",
    "        return nx.transitivity(self.ng)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def periphery(self): #f-28\n",
    "        try:\n",
    "            return len(nx.periphery(self.ng))/float(self.N)\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    def cycle_basis(self): #f-29\n",
    "        return len(nx.cycle_basis(self.ng))\n",
    "    \n",
    "    \n",
    "    def square_clustering_coefficient(self): #f-30\n",
    "        all_sqr = 0\n",
    "        sqr = 0\n",
    "        for root in xrange(self.N):\n",
    "            for j in xrange(self.N):\n",
    "                for i in xrange(self.N):\n",
    "                    for u in xrange(self.N):\n",
    "                        if root != i and root != j and i < j and u != i and u != j and u != root:\n",
    "                            if self.matrix[root][i] and self.matrix[root][j]:\n",
    "                                all_sqr += 1\n",
    "                                if self.matrix[i][u] and self.matrix[j][u]:\n",
    "                                    sqr += 1\n",
    "        all_sqr += sqr\n",
    "        sqr = sqr/4\n",
    "        return sqr/float(all_sqr) if all_sqr else 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import_index = {no_normal:[], range_normal:[], z_normal:[]}\n",
    "for k in effectiveness:\n",
    "    for l in effectiveness[k]:\n",
    "        if len(l) == 20:\n",
    "            s_l = sorted(l)\n",
    "            for place in xrange(-1, -6, -1):\n",
    "                import_index[k].append(l.index(s_l[place]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<function __main__.range_normal>: [12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19],\n",
       " <function __main__.z_normal>: [12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19],\n",
       " <function __main__.no_normal>: [12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  13,\n",
       "  2,\n",
       "  19]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for func in import_index:\n",
    "    print func\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
